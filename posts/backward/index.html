<!doctype html><html>
<head>
<title>Backward propagation using matrix notations</title>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="ie=edge">
<link rel=stylesheet href=/css/bootstrap.min.css>
<link rel=stylesheet href=/css/layouts/main.css>
<link rel=stylesheet href=/css/navigators/navbar.css>
<link rel=stylesheet href=/css/plyr.css>
<link rel=stylesheet href=/css/flag-icon.min.css>
<link href="https://fonts.googleapis.com/css2?family=Muli:wght@300;400;500;600" rel=stylesheet>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css>
<link rel=icon type=image/png href=/images/site/favicon3_hu62e62282d1df9a6f522c194700ff0a75_33785_42x0_resize_box_3.png>
<meta property="og:title" content="Backward propagation using matrix notations">
<meta property="og:description" content="An explanation of the mathematics behind backward propagation.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://arthurzucker.github.io/posts/backward/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-11-09T00:00:00+00:00">
<meta property="article:modified_time" content="2021-11-09T00:00:00+00:00">
<meta name=description content="An explanation of the mathematics behind backward propagation.">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/atom-one-dark.min.css>
<link rel=stylesheet href=/css/layouts/single.css>
<link rel=stylesheet href=/css/navigators/sidebar.css>
<link rel=stylesheet href=/css/style.css>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YRJ694EF5C"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-YRJ694EF5C',{anonymize_ip:!1})}</script>
</head>
<body data-spy=scroll data-target=#TableOfContents data-offset=80>
<div class="container-fluid bg-dimmed wrapper">
<nav class="navbar navbar-expand-xl top-navbar final-navbar shadow">
<div class=container>
<button class="navbar-toggler navbar-light" id=sidebar-toggler type=button onclick=toggleSidebar()>
<span class=navbar-toggler-icon></span>
</button>
<a class=navbar-brand href=/>
<img src=/images/site/favicon3_hu62e62282d1df9a6f522c194700ff0a75_33785_42x0_resize_box_3.png alt=Logo>
Arthur Zucker's Portfolio</a>
<button class="navbar-toggler navbar-light" id=toc-toggler type=button onclick=toggleTOC()>
<span class=navbar-toggler-icon></span>
</button>
<div class="collapse navbar-collapse lang-selector" id=top-nav-items>
<ul class="navbar-nav ml-auto">
</ul>
</div>
</div>
<img src=/images/site/favicon3_hu62e62282d1df9a6f522c194700ff0a75_33785_42x0_resize_box_3.png class=d-none id=main-logo alt=Logo>
<img src=/images/site/favicon4_hu5db1c7af89e12ca8c711bcc33bb3007c_15810_42x0_resize_box_3.png class=d-none id=inverted-logo alt="Inverted Logo">
</nav>
<section class=sidebar-section id=sidebar-section>
<div class=sidebar-holder>
<div class=sidebar id=sidebar>
<form class=mx-auto method=get action=/search>
<input type=text name=keyword placeholder=Search data-search id=search-box>
</form>
<div class=sidebar-tree>
<ul class=tree id=tree>
<li id=list-heading><a href=/posts data-filter=all>Posts</a></li>
<div class=subtree>
<li>
<i class="fas fa-plus-circle"></i><a href=/posts/flying-foxes-study/>Passive Acoustic Monitoring Using AI</a>
<ul>
<li>
<i class="fas fa-plus-circle"></i><a href=/posts/flying-foxes-study/ai/>Deep Learning pipeline</a>
<ul>
<li><a href=/posts/flying-foxes-study/ai/aed/ title="Audio Event Detection">Audio Event Detection</a></li>
<li><a href=/posts/flying-foxes-study/ai/speaker/ title="Speaker Recognition">Speaker Recognition</a></li>
</ul>
</li>
<li><a href=/posts/flying-foxes-study/ecology/ title=Ecology>Ecology</a></li>
</ul>
</li>
<li>
<i class="fas fa-plus-circle"></i><a href=/posts/projects/>Projects</a>
<ul>
<li><a href=/posts/projects/safran/ title="Semantic Segmentation for cars">Semantic Segmentation for cars</a></li>
<li><a href=/posts/projects/clusti/ title="Table Structure Recognition">Table Structure Recognition</a></li>
</ul>
</li>
<li>
<i class="fas fa-plus-circle"></i><a href=/posts/mva/>MVA Courses</a>
<ul>
<li>
<i class="fas fa-plus-circle"></i><a href=/posts/mva/recvis/>Computer Vision & Object Recognition</a>
<ul>
<li><a href=/posts/mva/recvis/lesson1/ title="Lesson 1">Lesson 1</a></li>
<li><a href=/posts/mva/recvis/lesson3/ title="Lesson 3">Lesson 3</a></li>
</ul>
</li>
<li>
<i class="fas fa-plus-circle"></i><a href=/posts/mva/deeplearning/>Deep Learning</a>
<ul>
<li><a href=/posts/mva/deeplearning/lesson2/ title="Lesson 2">Lesson 2</a></li>
</ul>
</li>
<li>
<i class="fas fa-plus-circle"></i><a href=/posts/mva/rl/>Reinforcement Learning</a>
<ul>
<li><a href=/posts/mva/rl/lesson1/ title="Lesson 1">Lesson 1</a></li>
<li><a href=/posts/mva/rl/lesson2/ title="Lesson 2">Lesson 2</a></li>
</ul>
</li>
</ul>
</li>
<li><a class=active href=/posts/backward/ title="Backward propagation">Backward propagation</a></li>
</div>
</ul>
</div>
</div>
</div>
</section>
<section class=content-section id=content-section>
<div class=content>
<div class="container p-0 read-area">
<div class="hero-area col-sm-12" id=hero-area style=background-image:url(https://arthurzucker.github.io/images/default-hero.jpg)>
</div>
<div class=page-content>
<div class="author-profile ml-auto align-self-lg-center">
<img class=rounded-circle src=/images/author/me_hue0c31f5a221a4dac786736a317c9bf63_45873_120x120_fit_q75_box.jpg alt="Author Image">
<h5 class=author-name>Arthur Zucker</h5>
<p>November 9, 2021</p>
</div>
<div class=title>
<h1>Backward propagation using matrix notations</h1>
</div>
<div class=taxonomy-terms>
<ul>
<li class=rounded><a href=/tags/ml class="btn, btn-sm">ML</a></li>
<li class=rounded><a href=/tags/backward-propagation class="btn, btn-sm">Backward Propagation</a></li>
<li class=rounded><a href=/tags/english class="btn, btn-sm">English</a></li>
</ul>
</div>
<div class=post-content id=post-content>
<style>r{color:Red}o{color:Orange}g{color:Green}b{color:Blue}</style>
<h2 id=introduction>Introduction</h2>
<p>$$
\begin{equation}
H=\text{ReLU}(W_i X+B_i)\
Y=W_oH+B_o
\tag{1}
\end{equation}
$$</p>
<p>where $X$ is the input, $Y$ is the output, $H$ is the hidden layer, and $W_i$, $W_o$, $B_i$ and $B_o$ are the network parameters that need to be trained. Here the subscripts $i$ and $o$ stand for the <em>input</em> and <em>output</em> layer, respectively. This network was also discussed in the class and is illustrated in the above figure where the input units are shown in green, the hidden units in blue and the output in yellow. This network is implemented in the function <code>nnet_forward_logloss</code>.</p>
<p>You will train the parameters of the network from labelled training data ${X^n,Y^n}$ where $X^n$ are points in $\mathbb{R}^2$ and $Y^n\in{-1,1}$ are labels for each point. You will use the stochastic gradient descent algorithm discussed in the class to minimize the loss of the network on the training data given by</p>
<p>\begin{equation}
L=\sum_n s(Y^n,\bar{Y}(X^n))
\tag{2}
\end{equation}</p>
<p>where $Y^n$ is the target label for the n-th example and $\bar{Y}(X^n)$ is the network‚Äôs output for the n-th example $X^n$. The skeleton of the training procedure is provided in the <code>train_loop</code> function.</p>
<p>We will use the logistic loss, which has the following form:</p>
<p>\begin{equation}
s(Y, \bar{Y}(X))=\log(1+\exp(-Y. \bar{Y}(X))
\tag{3}
\end{equation}</p>
<p>where $Y$ is the target label and $\bar{Y}(X)$ is the output of the network for input example $X$. With the logistic loss, the output of the network can be interpreted as a probability $P(\text{class}=1|X) =\sigma(X)$ , where $\sigma(X) =1/(1+\exp(-X))$ is the sigmoid function. Note also that $P(\text{class}=-1|X)=1-P(\text{class}=1|X)$.</p>
<p>Given that in the next task, X will be a 2D vector representing the input vector, I will answer to this question with $X$ as a vector of input and not a matrix ( if X represented a batch of input, the computation would be a bit different).</p>
<p>So let $X\in \mathbb{R}^{d}$ with $d$ the dimension of $X$. Let&rsquo;s start by computing the local gradients associated with each neurones.</p>
<ul>
<li>
<p>Given X, we have the first neuron which outputs $H = ReLu(W_i \times X + B_i)$ with $H\in \mathbb{R}^{h}, B_i \in \mathbb{R}^{h}, W_i\in \mathbb{R}^{hxd}, X \in ‚Ñù^{d}$. The 2 local gradients that can be computed are the following: $\frac{\partial H}{\partial W_i} $ and $\frac{\partial H}{\partial B_i} $.</p>
<ul>
<li>
<p>$\frac{\partial H}{\partial W_i} $ : the derivative of a vector by a matrix is quite uncommon and it&rsquo;s the first time I am getting involved with it. We have that $W_i \in ‚Ñù^{hxd}$ (yes, in the previous definition, in order to compute $W_iX$, the dimensions should be $(hxd)\times h$, with X a row vector, but the next function uses a different format for W). Based on the litterature <a href=#fn1><sup>1</sup></a> <a href=#fn2><sup>2</sup></a> , the derivative of $\frac{\partial W_i X + B_i}{\partial W_i} = X \otimes I_h \in ‚Ñù^{hd \times h } $ with $\otimes$ the Kronecher product, and $I_h$ the identity square matrix of dimension $h$. We thus deduce that : $$\frac{\partial H}{\partial W_i} = diag(ùüô_{W_i \times X + B_i \succeq 0 }) X \otimes I_h $$ . Note that $diag(ùüô_{W_i \times X + B_i \succeq 0 })$ is a matrix of $‚Ñù^{h\times h}$.The dimension of this partial derivative is $ (h, h)\times (h \times hd) $. Which gives a vector of dimensions $h\times hd$.</p>
</li>
<li>
<p>$\frac{\partial H}{\partial B_i} $ : here the computation is straight forward, we can conclude that $\frac{\partial H}{\partial B_i} = diag(ùüô_{W_i \times X + B_i \succeq 0 })$ with dimension $h\times h$.</p>
</li>
</ul>
</li>
<li>
<p>The second neuron which outputs $\bar Y = W_o \times H + B_o$ also has 2 local gradients that can be computed on the fly: $\frac{\partial \bar Y}{\partial W_o} $ and $\frac{\partial \bar Y}{\partial B_o} $.</p>
<ul>
<li>
<p>$\frac{\partial \bar Y}{\partial W_o}= H $ . The dimension of this partial derivative is $h$. It is the derivative of a scalar by a vector, which gives a vector.</p>
</li>
<li>
<p>$\frac{\partial \bar Y}{\partial B_o}= 1$ , since $B_0$ is a scalar, and Y is a scalar.</p>
</li>
<li>
<p>$\frac{\partial \bar Y}{\partial H}= W_0$ which is of size $h$.</p>
</li>
</ul>
</li>
<li>
<p>Finally, we can compute the derivates relative to the loss function $s(Y,\bar Y)$.</p>
</li>
<li>
<p>Note that $Y$ and $\bar Y$ are both scalars, $ \frac{\partial s(Y, \bar{Y})}{\partial \bar Y} = \frac{-Y \exp(-Y. \bar{Y})}{1+\exp(-Y. \bar{Y})} = -Y.œÉ(-Y\bar Y)$ which is a scalar.</p>
</li>
<li>
<p>$ \frac{\partial s(Y, \bar{Y})}{\partial W_o} =\frac{\partial s(Y, \bar{Y})}{\partial \bar Y}\frac{\partial \bar{Y}}{\partial W_o} = -Y.œÉ(-Y\bar Y) H $</p>
</li>
<li>
<p>$ \frac{\partial s(Y, \bar{Y})}{\partial B_o} =\frac{\partial s(Y, \bar{Y})}{\partial \bar Y}\frac{\partial \bar{Y}}{\partial B_o} = -Y.œÉ(-Y\bar Y) $</p>
</li>
<li>
<p>$ \frac{\partial s(Y, \bar{Y})}{\partial W_i} =\frac{\partial s(Y, \bar{Y})}{\partial \bar Y}\frac{\partial \bar{Y}}{\partial H} \frac{\partial H}{\partial W_i} = -Y.œÉ(-Y\bar Y) W_0 diag(ùüô_{W_i \times X + B_i \succeq 0 }) X \otimes I_h$</p>
</li>
<li>
<p>$ \frac{\partial s(Y, \bar{Y})}{\partial B_i} =\frac{\partial s(Y, \bar{Y})}{\partial \bar Y}\frac{\partial \bar{Y}}{\partial H} \frac{\partial H}{\partial B_i} = -Y.œÉ(-Y\bar Y) W_0 diag(ùüô_{W_i \times X + B_i \succeq 0 }) $</p>
</li>
</ul>
<p>In the next function, it is important to note that the dimension of $W_i$ is incorrect (compared to the notations introduced in this section), indeed, the matrix $W_i \in ‚Ñù^{d\times h}$ instead of $W_i \in ‚Ñù^{h\times d}$. This changes the dimensions of the results I</p>
<h2 id=implementation->Implementation :</h2>
<pre tabindex=0><code>def ind(H):
  return (H&gt;0)*1.0
def gradient_nn(X, Y, Wi, bi, Wo, bo):
    '''
    Compute gradient of the logistic loss of the neural network on example X with
    target label Y, with respect to the parameters Wi,bi,Wo,bo.

    Input:
        X ... 2d vector of the input example
        Y ... the target label in {-1,1}   
        Wi,bi,Wo,bo ... parameters of the network
        Wi ... [dxh] 
        bi ... [h] 
        Wo ... [h]
        bo ... 1
        where h... is the number of hidden units
              d... is the number of input dimensions (d=2)

    Output: 
        grad_s_Wi [dxh] ... gradient of loss s(Y,Y(X)) w.r.t  Wi
        grad_s_bi [h]   ... gradient of loss s(Y,Y(X)) w.r.t. bi
        grad_s_Wo [h]   ... gradient of loss s(Y,Y(X)) w.r.t. Wo
        grad_s_bo 1     ... gradient of loss s(Y,Y(X)) w.r.t. bo
    '''
    # THe operators and the format of X does not allow for the same implementation as 
    # what is described in the previous theoretical answer. 
    H = np.maximum(np.matmul(X,Wi) + bi, 0)
    Yo = np.dot(Wo, H) + bo
    h,d = len(Wo), len(X)
    grad_s_bo = -Y*sigm(-Y*Yo)                                    # scalar
    grad_s_Wo = grad_s_bo*H                                       # (h,)  
    grad_h_Wi = (np.diag(ind(H)) @ np.kron(X,np.eye(h)))          # hxh @ ( h x (h,d)) which can be reshaped
    grad_s_Wi = grad_s_bo * ( Wo @ grad_h_Wi).reshape(d,h)       
    grad_s_bi = grad_s_bo*Wo@np.diag(ind(H))                      # h \times h,h gives h 
    return grad_s_Wi,grad_s_bi,grad_s_Wo,grad_s_bo
    ##########################    
</code></pre>
</div>
<div class="row pl-3 pr-3">
<div class="col-md-6 share-buttons">
<strong>Share on:</strong>
<a class="btn btn-sm facebook-btn" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2farthurzucker.github.io%2fposts%2fbackward%2f" target=_blank>
<i class="fab fa-facebook"></i>
</a>
<a class="btn btn-sm twitter-btn" href="https://twitter.com/share?url=https%3a%2f%2farthurzucker.github.io%2fposts%2fbackward%2f&text=Backward%20propagation%20using%20matrix%20notations&via=Arthur%20Zucker%27s%20Portfolio" target=_blank>
<i class="fab fa-twitter"></i>
</a>
<a class="btn btn-sm reddit-btn" href="https://reddit.com/submit?url=https%3a%2f%2farthurzucker.github.io%2fposts%2fbackward%2f&title=Backward%20propagation%20using%20matrix%20notations" target=_blank>
<i class="fab fa-reddit"></i>
</a>
<a class="btn btn-sm linkedin-btn" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2farthurzucker.github.io%2fposts%2fbackward%2f&title=Backward%20propagation%20using%20matrix%20notations" target=_blank>
<i class="fab fa-linkedin"></i>
</a>
<a class="btn btn-sm whatsapp-btn" href="https://api.whatsapp.com/send?text=Backward%20propagation%20using%20matrix%20notations https%3a%2f%2farthurzucker.github.io%2fposts%2fbackward%2f" target=_blank>
<i class="fab fa-whatsapp"></i>
</a>
<a class="btn btn-sm email-btn" href="mailto:?subject=Backward%20propagation%20using%20matrix%20notations&body=https%3a%2f%2farthurzucker.github.io%2fposts%2fbackward%2f" target=_blank>
<i class="fas fa-envelope-open-text"></i>
</a>
</div>
<div class="col-md-6 btn-improve-page">
<a href=https://github.com/ArthurZucker/ArthurZucker.github.io/edit/main/content/posts/backward.md title="Improve this page" target=_blank rel=noopener>
<i class="fas fa-code-branch"></i>
Improve this page
</a>
</div>
</div>
<hr>
<div class="row next-prev-navigator">
<div class="col-md-6 previous-article">
<a href=/posts/mva/rl/lesson2/ title="Reinforcement learning, lesson 2" class="btn btn-outline-info">
<div><i class="fas fa-chevron-circle-left"></i> Prev</div>
<div class=next-prev-text>Reinforcement learning, lesson 2</div>
</a>
</div>
</div>
<hr>
</div>
</div>
</div>
<a id=scroll-to-top class=btn><i class="fas fa-chevron-circle-up"></i></a>
</section>
<section class=toc-section id=toc-section>
<div class=toc-holder>
<h5 class="text-center pl-3">Table of Contents</h5>
<hr>
<div class=toc>
<nav id=TableOfContents>
<ul>
<li><a href=#introduction>Introduction</a></li>
<li><a href=#implementation->Implementation :</a></li>
</ul>
</nav>
</div>
</div>
</section>
</div>
<footer class="container-fluid text-center align-content-center footer pb-2">
<div class="container pt-5">
<div class="row text-left">
<div class="col-md-4 col-sm-12">
<h5>Navigation</h5>
<ul>
<li class=nav-item>
<a class=smooth-scroll href=/#about>About</a>
</li>
<li class=nav-item>
<a class=smooth-scroll href=/#skills>Skills</a>
</li>
<li class=nav-item>
<a class=smooth-scroll href=/#experiences>Experiences</a>
</li>
<li class=nav-item>
<a class=smooth-scroll href=/#education>Education</a>
</li>
<li class=nav-item>
<a class=smooth-scroll href=/#projects>Projects</a>
</li>
<li class=nav-item>
<a class=smooth-scroll href=/#recent-posts>Recent Posts</a>
</li>
<li class=nav-item>
<a class=smooth-scroll href=/#accomplishments>Accomplishments</a>
</li>
<li class=nav-item>
<a class=smooth-scroll href=/#achievements>Achievements</a>
</li>
</ul>
</div>
<div class="col-md-4 col-sm-12">
<h5>Contact me:</h5>
<ul>
<li><span>Email: </span> <span>arthur.zucker@ens-paris-saclay.fr</span></li>
</ul>
</div>
</div>
</div>
</footer>
<script type=text/javascript src=/js/jquery-3.4.1.min.js></script>
<script type=text/javascript src=/js/popper.min.js></script>
<script type=text/javascript src=/js/bootstrap.min.js></script>
<script type=text/javascript src=/js/navbar.js></script>
<script type=text/javascript src=/js/plyr.js></script>
<script type=text/javascript src=/js/main.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js></script>
<script src=/js/single.js></script>
<script>hljs.initHighlightingOnLoad()</script>
<script>window.MathJax={tex:{inlineMath:[['$','$']]},options:{enableMenu:!0}}</script>
<script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script>
<style>mjx-container.MathJax[display=inline]{font-size:150%!important}mjx-container.MathJax[display=true]{text-align:left!important}@media screen and (min-width:600px){mjx-container.MathJax[display=true]{padding-left:2rem}}</style>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css integrity=sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq crossorigin=anonymous>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js integrity=sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script>
</body>
</html>